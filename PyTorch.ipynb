{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is a popular open-source machine learning library for Python that provides a flexible and efficient framework for building deep learning models. It offers dynamic computational graphs, automatic differentiation, and GPU acceleration capabilities. Here's an explanation of PyTorch along with some examples:\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tensor Basics:\n",
    "\n",
    "At the core of PyTorch is the torch.Tensor class, which represents a multi-dimensional array. Tensors are similar to NumPy arrays but with additional functionality optimized for deep learning computations. Here's an example of creating and manipulating tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "# Perform operations on tensors\n",
    "y = x + 2\n",
    "z = torch.sin(x)\n",
    "\n",
    "# Access tensor properties\n",
    "print(x.size())  # Output: torch.Size([4])\n",
    "print(x.dtype)  # Output: torch.int64\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Automatic Differentiation:\n",
    "PyTorch provides automatic differentiation, which is crucial for training deep learning models. The torch.Tensor class keeps track of the operations performed on it, allowing you to compute gradients with respect to the tensor. Here's an example of computing gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor with requires_grad=True\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "\n",
    "# Perform operations\n",
    "y = x.pow(2).sum()\n",
    "\n",
    "# Compute gradients\n",
    "y.backward()\n",
    "\n",
    "# Access gradients\n",
    "print(x.grad)  # Output: tensor([2., 4.])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Neural Network Building:\n",
    "PyTorch provides a module called torch.nn for building neural networks. It includes various layers, activation functions, and loss functions. Here's an example of building a simple neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a neural network class\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc = nn.Linear(10, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the neural network\n",
    "net = SimpleNet()\n",
    "\n",
    "# Perform forward pass\n",
    "input_data = torch.randn(1, 10)\n",
    "output = net(input_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Training:\n",
    "PyTorch simplifies the training process through optimization techniques and utilities. Here's an example of training a neural network using a simple gradient descent approach:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we define a neural network class SimpleNet, a loss function (nn.MSELoss), and an optimizer (torch.optim.SGD) to perform gradient descent. We then iterate over a specified number of epochs and perform the training loop. During each epoch, we compute the forward pass, calculate the loss, perform the backward pass to compute gradients, and update the network parameters using the optimizer's step() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.741607427597046\n",
      "Epoch: 2, Loss: 0.8525292277336121\n",
      "Epoch: 3, Loss: 1.4487330913543701\n",
      "Epoch: 4, Loss: 0.5463422536849976\n",
      "Epoch: 5, Loss: 1.8438800573349\n",
      "Epoch: 6, Loss: 2.094611644744873\n",
      "Epoch: 7, Loss: 1.4918582439422607\n",
      "Epoch: 8, Loss: 1.0030653476715088\n",
      "Epoch: 9, Loss: 0.8730376958847046\n",
      "Epoch: 10, Loss: 1.818778395652771\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the neural network class and loss function\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc = nn.Linear(10, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "net = SimpleNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    input_data = torch.randn(1, 10)\n",
    "    target = torch.randn(1, 5)\n",
    "    output = net(input_data)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. GPU Acceleration:\n",
    "PyTorch supports GPU acceleration, allowing you to leverage the computational power of GPUs for faster training. Here's an example of moving tensors and models to the GPU:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By checking the availability of a GPU using torch.cuda.is_available(), you can dynamically choose to use the GPU (\"cuda\") or the CPU (\"cpu\"). The .to(device) method is used to move tensors and models to the specified device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (fc): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move tensors to GPU\n",
    "x = torch.tensor([1, 2, 3]).to(device)\n",
    "\n",
    "# Move model to GPU\n",
    "net = SimpleNet()\n",
    "net.to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples provide a glimpse into the capabilities of PyTorch for tensor manipulation, automatic differentiation, neural network building, model training, and GPU acceleration. PyTorch offers a rich set of functionalities to support various deep learning tasks and enables researchers and practitioners to build and experiment with complex models with ease."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
